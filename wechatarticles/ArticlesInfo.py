# coding:  utf-8
import re

import requests
from bs4 import BeautifulSoup as bs


class ArticlesInfo(object):
    """ç™»å½•WeChatï¼Œè·å–æ›´åŠ è¯¦ç»†çš„æ¨æ–‡ä¿¡æ¯ã€‚å¦‚ç‚¹èµæ•°ã€é˜…è¯»æ•°ã€è¯„è®ºç­‰"""

    def __init__(self, appmsg_token, cookie, proxies={"http": None, "https": None}):
        """
        åˆå§‹åŒ–å‚æ•°

        Parameters
        ----------
        cookie: str
            ç‚¹å¼€å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æŠ“åŒ…å·¥å…·è·å–çš„cookie
        appmsg_token: str
            ç‚¹å¼€å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æŠ“åŒ…å·¥å…·è·å–çš„appmsg_token
        """
        self.s = requests.session()
        self.s.trust_env = False
        self.appmsg_token = appmsg_token
        self.headers = {
            "User-Agent": "Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0Chrome/57.0.2987.132 MQQBrowser/6.2 Mobile",
            "Cookie": cookie,
        }
        self.data = {
            "is_only_read": "1",
            "is_temp_url": "0",
            "appmsg_type": "9",  # æ–°å‚æ•°ï¼Œä¸åŠ å…¥æ— æ³•è·å–like_num
        }
        self.proxies = proxies
        self.too_frequently_text = "ä½ çš„è®¿é—®è¿‡äºé¢‘ç¹ï¼Œéœ€è¦ä»å¾®ä¿¡æ‰“å¼€éªŒè¯èº«ä»½ï¼Œæ˜¯å¦éœ€è¦ç»§ç»­è®¿é—®å½“å‰é¡µé¢"

    def __verify_url(self, article_url):
        """
        ç®€å•éªŒè¯æ–‡ç« urlæ˜¯å¦ç¬¦åˆè¦æ±‚

        Parameters
        ----------
        article_url: str
            æ–‡ç« é“¾æ¥
        """
        verify_lst = ["mp.weixin.qq.com", "__biz", "mid", "sn", "idx"]
        for string in verify_lst:
            if string not in article_url:
                raise Exception("params is error, please check your article_url")

    def read_like_nums(self, article_url):
        """
        è·å–é˜…è¯»æ•°å’Œç‚¹èµæ•°

        Parameters
        ----------
        article_url: str
            æ–‡ç« é“¾æ¥

        Returns
        -------
        (int, int):
            é˜…è¯»æ•°ã€ç‚¹èµæ•°
        """
        import logging
        logger = logging.getLogger(__name__)
        
        try:
            logger.debug(f"         [read_like_nums] è°ƒç”¨ __get_appmsgext...")
            appmsgext_result = self.__get_appmsgext(article_url)
            logger.debug(f"         [read_like_nums] __get_appmsgext è¿”å›: {appmsgext_result}")
            
            appmsgstat = appmsgext_result["appmsgstat"]
            logger.debug(f"         [read_like_nums] appmsgstat: {appmsgstat}")
            
            read_num = appmsgstat["read_num"]
            like_num = appmsgstat["like_num"]
            old_like_num = appmsgstat["old_like_num"]
            
            logger.debug(f"         [read_like_nums] æå–æ•°æ®: read={read_num}, like={like_num}, old_like={old_like_num}")
            
            return (read_num, like_num, old_like_num)
        except Exception as e:
            logger.error(f"         [read_like_nums] å¼‚å¸¸: {e}")
            import traceback
            logger.error(f"         [read_like_nums] å †æ ˆ: {traceback.format_exc()}")
            raise Exception("params is error, please check your article_url")

    def comments(self, article_url):
        """
        è·å–æ–‡ç« è¯„è®º

        Parameters
        ----------
        article_url: str
            æ–‡ç« é“¾æ¥

        Returns
        -------
        json::

            {
                "base_resp": {
                    "errmsg": "ok",
                    "ret": 0
                },
                "elected_comment": [
                    {
                        "content": ç”¨æˆ·è¯„è®ºæ–‡å­—,
                        "content_id": "6846263421277569047",
                        "create_time": 1520098511,
                        "id": 3,
                        "is_from_friend": 0,
                        "is_from_me": 0,
                        "is_top": 0, æ˜¯å¦è¢«ç½®é¡¶
                        "like_id": 10001,
                        "like_num": 3,
                        "like_status": 0,
                        "logo_url": "http://wx.qlogo.cn/mmhead/OibRNdtlJdkFLMHYLMR92Lvq0PicDpJpbnaicP3Z6kVcCicLPVjCWbAA9w/132",
                        "my_id": 23,
                        "nick_name": è¯„è®ºç”¨æˆ·çš„åå­—,
                        "reply": {
                            "reply_list": [ ]
                        }
                    }
                ],
                "elected_comment_total_cnt": 3, è¯„è®ºæ€»æ•°
                "enabled": 1,
                "friend_comment": [ ],
                "is_fans": 1,
                "logo_url": "http://wx.qlogo.cn/mmhead/Q3auHgzwzM6GAic0FAHOu9Gtv5lEu5kUqO6y6EjEFjAhuhUNIS7Y2AQ/132",
                "my_comment": [ ],
                "nick_name": å½“å‰ç”¨æˆ·å,
                "only_fans_can_comment": false
            }
        """
        __biz, _, idx, _ = self.__get_params(article_url)
        getcomment_url = "https://mp.weixin.qq.com/mp/appmsg_comment?action=getcomment&__biz={}&idx={}&comment_id={}&limit=100"
        try:
            comment_id = self.__get_comment_id(article_url)
            if comment_id == "":
                return {}
            url = getcomment_url.format(__biz, idx, comment_id)
            return self.s.get(url, headers=self.headers, proxies=self.proxies).json()
        except Exception as e:
            print(e)
            return {}

    def __get_comment_id(self, article_url):
        """
        è·å–comment_id

        Parameters
        ----------
        article_url: str
            æ–‡ç« é“¾æ¥

        Returns
        -------
        str:
            comment_idè·å–è¯„è®ºå¿…è¦å‚æ•°
        """
        res = self.s.get(article_url, data=self.data, proxies=self.proxies)
        # ä½¿ç”¨æ­£åˆ™æå–comment_id
        comment_id = re.findall(r'comment_id = "(\d+)"', res.text)
        # å¢åŠ å…¶ä»–æƒ…å†µï¼Œæ„Ÿè°¢@[harry7756](https://github.com/harry7756)å»ºè®®
        if len(comment_id) == 0:
            comment_id = re.findall(r"(?<=comment_id.DATA\'\)\s\:\s\')[0-9]+", res.text)
        if len(comment_id) > 0:
            return comment_id[0]
        return ""

    def __get_params(self, article_url):
        """
        è§£ææ–‡ç« url, è·å–å¿…è¦çš„è¯·æ±‚å‚æ•°

        Parameters
        ----------
        article_url: str
            æ–‡ç« é“¾æ¥

        Returns
        -------
        (str, str, str, str):
            __biz, mid, idx, sn
        """
        # ç®€å•éªŒè¯æ–‡ç« çš„urlæ˜¯å¦æ­£ç¡®
        self.__verify_url(article_url)
        # åˆ‡åˆ†url, æå–ç›¸åº”çš„å‚æ•°
        string_lst = article_url.split("?")[1].split("&")
        dict_value = [string[string.index("=") + 1 :] for string in string_lst]
        __biz, mid, idx, sn, *_ = dict_value
        sn = sn[:-3] if sn[-3] == "#" else sn

        return __biz, mid, idx, sn

    def __get_appmsgext(self, article_url):
        """
        è·å–æ¯ç¯‡æ–‡ç« å…·ä½“ä¿¡æ¯

        Parameters
        ----------
        article_url: str
            æ–‡ç« é“¾æ¥

        Returns
        -------
        json:
            æ–‡ç« å…·ä½“ä¿¡æ¯çš„json::

                {
                    'advertisement_info': [],
                    'advertisement_num': 0,
                    'appmsgstat': {'is_login': True,
                    'like_num': 12,
                    'liked': False,
                    'read_num': 288,
                    'real_read_num': 0,
                    'ret': 0,
                    'show': True},
                    'base_resp': {'wxtoken': 2045685972},
                    'reward_head_imgs': []
                }
        """
        import logging
        logger = logging.getLogger(__name__)
        
        __biz, mid, idx, sn = self.__get_params(article_url)
        
        logger.debug(f"         [__get_appmsgext] æ–‡ç« å‚æ•°: __biz={__biz}, mid={mid}, idx={idx}, sn={sn[:20]}...")

        # å°†paramså‚æ•°æ¢åˆ°dataä¸­è¯·æ±‚ã€‚è¿™ä¸€æ­¥è²Œä¼¼ä¸æ¢ä¹Ÿè¡Œ
        origin_url = "https://mp.weixin.qq.com/mp/getappmsgext?"
        appmsgext_url = origin_url + "appmsg_token={}&x5=0".format(self.appmsg_token)
        self.data["__biz"] = __biz
        self.data["mid"] = mid
        self.data["sn"] = sn
        self.data["idx"] = idx

        logger.debug(f"         [__get_appmsgext] è¯·æ±‚ URL: {appmsgext_url[:80]}...")
        logger.debug(f"         [__get_appmsgext] è¯·æ±‚ data: {self.data}")
        
        # appmsgext_url = origin_url + "__biz={}&mid={}&sn={}&idx={}&appmsg_token={}&x5=1".format(
        #     __biz, mid, sn, idx, self.appmsg_token)
        response = requests.post(
            appmsgext_url, headers=self.headers, data=self.data, proxies=self.proxies
        )
        
        logger.info(f"         [__get_appmsgext] API å“åº”çŠ¶æ€ç : {response.status_code}")
        
        try:
            appmsgext_json = response.json()
        except Exception as json_error:
            logger.error(f"         [__get_appmsgext] âŒ JSON è§£æå¤±è´¥: {json_error}")
            logger.error(f"         [__get_appmsgext] åŸå§‹å“åº”å†…å®¹: {response.text[:500]}")
            raise
        
        logger.info(f"         [__get_appmsgext] API å“åº” JSON keys: {list(appmsgext_json.keys())}")
        logger.debug(f"         [__get_appmsgext] API å®Œæ•´å“åº”: {appmsgext_json}")

        if "appmsgstat" not in appmsgext_json.keys():
            logger.warning(f"         [__get_appmsgext] âš ï¸  å“åº”ä¸­æ²¡æœ‰ appmsgstat å­—æ®µï¼")
            logger.warning(f"         [__get_appmsgext] å®Œæ•´å“åº”: {appmsgext_json}")
            logger.warning(f"         [__get_appmsgext] ğŸ’¡ å¯èƒ½åŸå› :")
            logger.warning(f"         [__get_appmsgext]    1. æœªå…³æ³¨è¯¥å…¬ä¼—å·ï¼ˆæœ€å¸¸è§ï¼‰")
            logger.warning(f"         [__get_appmsgext]    2. Cookie æˆ– appmsg_token å·²è¿‡æœŸ")
            logger.warning(f"         [__get_appmsgext]    3. è¯¥å…¬ä¼—å·è®¾ç½®äº†éšç§ä¿æŠ¤")
            raise Exception("get info error, please check your cookie and appmsg_token")
        
        logger.debug(f"         [__get_appmsgext] appmsgstat å†…å®¹: {appmsgext_json.get('appmsgstat')}")
        return appmsgext_json

    def __get_content(self, url):
        return self.s.get(url.strip(), headers=self.headers, proxies=self.proxies).text

    def content(self, url, html_text=None):
        if html_text == None:
            html_text = self.__get_content(url)

        soup = bs(html_text, "lxml")
        if self.too_frequently_text in html_text:
            raise SystemError("è®¿é—®é¢‘ç¹ï¼")
        # jsåŠ è½½
        # html.text.split('var content = ')[1].split('var')[0].strip()
        # soup.find(id="js_panel_like_title").text
        try:
            body = soup.find(class_="rich_media_area_primary_inner")
            content_p = body.find(class_="rich_media_content")
            if content_p:
                imgs = body.find_all("img")
                return content_p.text.strip(), len(content_p.text.strip()), len(imgs)
            else:
                content_p = soup.find(id="js_panel_like_title").text.strip()
                return content_p, len(content_p), 0
        except:
            return "", 0, 0

    def complete_content(self, url, html_text=None):
        if html_text == None:
            html_text = self.__get_content(url)

        innerlink_flag = 0
        video_flag = 0
        imgs_flag = 0
        account_key_string_lst = [
            "æ­¤å¸å·å·²è¢«å±è”½, å†…å®¹æ— æ³•æŸ¥çœ‹",
            "è¯¥å…¬ä¼—å·å·²è¿ç§»",
            "æ­¤å¸å·å·²è‡ªä¸»æ³¨é”€ï¼Œå†…å®¹æ— æ³•æŸ¥çœ‹",
            "æ­¤å¸å·å¤„äºå¸å·è¿ç§»æµç¨‹ä¸­",
            "æ­¤å¸å·è¢«æŠ•è¯‰ä¸”ç»å®¡æ ¸æ¶‰å«Œä¾µæƒã€‚æ­¤å¸å·å·²æ³¨é”€ï¼Œå†…å®¹æ— æ³•æŸ¥çœ‹ã€‚",
        ]
        key_string_lst = [
            "è¯¥å†…å®¹å·²è¢«å‘å¸ƒè€…åˆ é™¤",
            "æ­¤å†…å®¹å› è¿è§„æ— æ³•æŸ¥çœ‹",
            "æ­¤å†…å®¹è¢«æŠ•è¯‰ä¸”ç»å®¡æ ¸æ¶‰å«Œä¾µæƒï¼Œæ— æ³•æŸ¥çœ‹ã€‚",
            "æ­¤å†…å®¹è¢«å¤šäººæŠ•è¯‰ï¼Œç›¸å…³çš„å†…å®¹æ— æ³•è¿›è¡ŒæŸ¥çœ‹ã€‚",
        ]

        if self.too_frequently_text in html_text:
            raise SystemError("è®¿é—®é¢‘ç¹ï¼")

        for key_string in key_string_lst:
            if key_string in html_text:
                title = key_string
                return (
                    "",
                    title,
                    "",
                    "",
                    imgs_flag,
                    innerlink_flag,
                    video_flag,
                )
        for key_string in account_key_string_lst:
            if key_string in html_text:
                title = key_string
                return (
                    "",
                    title,
                    "",
                    "",
                    imgs_flag,
                    innerlink_flag,
                    video_flag,
                )

        try:
            title = html_text.split("<h2")[1].split("</h2")[0].split(">")[1].strip()
        except Exception as e:
            title = ""

        if 'ct = "' in html_text:
            timestamp = int(html_text.split('ct = "')[1].split('";')[0].strip())
        else:
            timestamp = (
                html_text.split("ct = ")[1].split("|| '")[1].split("'")[0].strip()
            )
            timestamp = int(timestamp) if timestamp != "" else 0

        if "copyright" in html_text:
            if '_copyright_stat = "' in html_text:
                copyright_stat = int(
                    html_text.split('_copyright_stat = "')[1].split('";')[0].strip()
                )
            else:
                copyright_stat = (
                    html_text.split("copyright_stat =")[1]
                    .split("|| '")[1]
                    .split("'")[0]
                    .strip()
                )
                copyright_stat = int(copyright_stat) if copyright_stat != "" else 0
        else:
            copyright_stat = 0

        if "nick_name = " in html_text:
            nickname = (
                html_text.split("nick_name = ")[1]
                .split("|| '")[1]
                .split("'")[0]
                .strip()
            )
        else:
            nickname = html_text.split('nickname = "')[1].split('";')[0].strip()

        soup = bs(html_text, "lxml")

        body = soup.find(class_="rich_media_area_primary_inner")
        imgs_flag = len(body.find_all("img"))
        a_lst = body.find_all("a")
        for a_item in a_lst:
            if "tab" in a_item.attrs.keys() and a_item.attrs["tab"] == "innerlink":
                innerlink_flag = 1
                break
        video_lst = body.find_all(class_="js_video_channel_container")
        if len(video_lst) > 0:
            video_flag = 1
        return (
            nickname,
            title,
            timestamp,
            copyright_stat,
            imgs_flag,
            innerlink_flag,
            video_flag,
        )
